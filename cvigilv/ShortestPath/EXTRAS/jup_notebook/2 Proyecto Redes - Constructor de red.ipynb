{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Proyecto Redes - Constructor de red\n",
    "## Idea\n",
    "La idea es que a partir del archivo de interacciones, archivo de nodos de ligandos y archivo de nodos de blancos se pueda construir una red de consulta completamente unificada, la cual se guarda como un archivo binario GraphTool.\n",
    "## Input\n",
    "Archivo de interacciones\n",
    "Archivo de nodos - ligandos  \n",
    "Archivo de nodos - blancos  \n",
    "## Output\n",
    "Archivo de red de consulta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modify to use other input files\n",
    "interactions_file = '/home/carlos/Dropbox/2018/Data/CC&D mk. 2/chembl23_GS3_v2.mphase_gt_0.txt.co'\n",
    "ligands_file = '/home/carlos/Dropbox/2018/Data/CC&D mk. 2/chembl23_GS3_v2.mphase_gt_0.txt.co.ul'\n",
    "targets_file = '/home/carlos/Dropbox/2018/Data/CC&D mk. 2/chembl23_GS3_v2.mphase_gt_0.txt.co.ut'\n",
    "#ligands_simmat = '/home/carlos/Dropbox/2018/Data/CC&D mk. 2/chembl23_GS3_v2.mphase_gt_0.txt.co.ul.tc'\n",
    "ligands_simmat = '/home/carlos/Dropbox/chembl23_GS3_v2.mphase_gt_0.fix.txt.smi.fpt.bin.tanmat.csv'\n",
    "targets_simmat = '/home/carlos/Dropbox/2018/Data/CC&D mk. 2/chembl23_GS3_v2.mphase_gt_0.txt.co.ut.id'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 5 entries of interactions file:\n",
      "\n",
      "          Target         Ligand T_Accession  \\\n",
      "0  CHEMBL1075104  CHEMBL1287853      Q5S007   \n",
      "1  CHEMBL1075104  CHEMBL1289926      Q5S007   \n",
      "2  CHEMBL1075104  CHEMBL1721885      Q5S007   \n",
      "3  CHEMBL1075104  CHEMBL1789941      Q5S007   \n",
      "4  CHEMBL1075104  CHEMBL1908397      Q5S007   \n",
      "\n",
      "                                              T_Name  \\\n",
      "0  Leucine-rich repeat serine/threonine-protein k...   \n",
      "1  Leucine-rich repeat serine/threonine-protein k...   \n",
      "2  Leucine-rich repeat serine/threonine-protein k...   \n",
      "3  Leucine-rich repeat serine/threonine-protein k...   \n",
      "4  Leucine-rich repeat serine/threonine-protein k...   \n",
      "\n",
      "                                    T_Pfam  min(ACT)  avg(ACT)  max(ACT)  \\\n",
      "0  PF00069,PF08477,PF12799,PF13855,PF16095     870.0     935.0    1000.0   \n",
      "1  PF00069,PF08477,PF12799,PF13855,PF16095     920.0     955.0     990.0   \n",
      "2  PF00069,PF08477,PF12799,PF13855,PF16095      70.0      71.0      72.0   \n",
      "3  PF00069,PF08477,PF12799,PF13855,PF16095      90.0     190.0     290.0   \n",
      "4  PF00069,PF08477,PF12799,PF13855,PF16095      45.0     197.5     350.0   \n",
      "\n",
      "                                            L_SMILES       Species  \\\n",
      "0  Cc1cnc(Nc2ccc(OCCN3CCCC3)cc2)nc1Nc4cccc(c4)S(=...  Homo sapiens   \n",
      "1  CNC(=O)c1ccccc1Sc2ccc3c(\\\\C=C\\\\c4ccccn4)n[nH]c3c2  Homo sapiens   \n",
      "2  Cc1[nH]c(\\\\C=C\\\\2/C(=O)Nc3ccc(F)cc23)c(C)c1C(=...  Homo sapiens   \n",
      "3        N#CC[C@H](C1CCCC1)n2cc(cn2)c3ncnc4[nH]ccc34  Homo sapiens   \n",
      "4     O=C(N1CCNCC1)c2ccc(\\\\C=C\\\\c3n[nH]c4ccccc34)cc2  Homo sapiens   \n",
      "\n",
      "   L_MaxPhase                                         T_Sequence  \n",
      "0           3  MASGSCQGCEEDEETLKKLIVRLNNVQEGKQIETLVQILEDLLVFT...  \n",
      "1           4  MASGSCQGCEEDEETLKKLIVRLNNVQEGKQIETLVQILEDLLVFT...  \n",
      "2           2  MASGSCQGCEEDEETLKKLIVRLNNVQEGKQIETLVQILEDLLVFT...  \n",
      "3           4  MASGSCQGCEEDEETLKKLIVRLNNVQEGKQIETLVQILEDLLVFT...  \n",
      "4           1  MASGSCQGCEEDEETLKKLIVRLNNVQEGKQIETLVQILEDLLVFT...  \n",
      "\n",
      "----------------------------------------------------------------\n",
      "\n",
      "First 5 entries of ligands node file:\n",
      "\n",
      "                                              SMILES    ChEMBL_ID\n",
      "0        OC(=O)COCCN1CCN(CC1)C(c2ccccc2)c3ccc(Cl)cc3   CHEMBL1000\n",
      "1                  CC(C)(C)NC[C@H](O)c1ccc(O)c(CO)c1   CHEMBL1002\n",
      "2  CC\\\\C(=C(/c1ccccc1)\\\\c2ccc(OCCN(C)C)cc2)\\\\c3cc...  CHEMBL10041\n",
      "3                                  NCCCNCCSP(=O)(O)O   CHEMBL1006\n",
      "4            CC(C)COCC(CN(Cc1ccccc1)c2ccccc2)N3CCCC3   CHEMBL1008\n",
      "\n",
      "----------------------------------------------------------------\n",
      "\n",
      "First 5 entries of targets node file:\n",
      "\n",
      "                                            Sequence      ChEMBL_ID\n",
      "0  MASGSCQGCEEDEETLKKLIVRLNNVQEGKQIETLVQILEDLLVFT...  CHEMBL1075104\n",
      "1  MARELRALLLWGRRLRPLLRAPALAAVPGGKPILCPRRTTAQLGPR...  CHEMBL1075132\n",
      "2  MVDMGALDNLIANTAYLQARKPSDCDSKELQRRRRSLALPGLQGCA...  CHEMBL1075133\n",
      "3  MSGMEKLQNASWIYQQKLEDPFQKHLNSTEEYLAFLCGPRRSHFFL...  CHEMBL1075144\n",
      "4  MAMTGSTPCSSMSNHTKERVTMTKVTLENFYSNLIAQHEEREMRQK...  CHEMBL1075155\n",
      "\n",
      "----------------------------------------------------------------\n",
      "\n",
      "Data summary:\n",
      "\n",
      "Target          897\n",
      "Ligand         1232\n",
      "T_Accession     897\n",
      "T_Name          896\n",
      "T_Pfam          343\n",
      "min(ACT)       2260\n",
      "avg(ACT)       3604\n",
      "max(ACT)       2414\n",
      "L_SMILES       1232\n",
      "Species           1\n",
      "L_MaxPhase        4\n",
      "T_Sequence      897\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load file to dataframes\n",
    "df_interactions = pd.read_csv(interactions_file, delimiter = '\\t', index_col = False)\n",
    "df_ligands = pd.read_csv(ligands_file, delimiter = '\\t', header = None, names = ['SMILES', 'ChEMBL_ID'], index_col = False)\n",
    "df_targets = pd.read_csv(targets_file, delimiter = '\\t', header = None, names = ['Sequence', 'ChEMBL_ID'], index_col = False)\n",
    "\n",
    "print('First 5 entries of interactions file:\\n')\n",
    "print(df_interactions.head())\n",
    "print('\\n' + '-'*64 + '\\n\\nFirst 5 entries of ligands node file:\\n')\n",
    "print(df_ligands.head())\n",
    "print('\\n' + '-'*64 + '\\n\\nFirst 5 entries of targets node file:\\n')\n",
    "print(df_targets.head())\n",
    "print('\\n' + '-'*64 + '\\n\\nData summary:\\n')\n",
    "print(df_interactions.nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 5 entries of processed Ligand similarity matrix:\n",
      "\n",
      "        Source      Target  Similarity  Distance  Z_Similarity  Z_Distance\n",
      "0   CHEMBL1002  CHEMBL1000    0.264706  0.735294      3.119216    8.664482\n",
      "1  CHEMBL10041  CHEMBL1000    0.294643  0.705357      3.471984    8.311714\n",
      "2  CHEMBL10041  CHEMBL1002    0.402299  0.597701      4.740570    7.043128\n",
      "3   CHEMBL1006  CHEMBL1000    0.083333  0.916667      0.981974   10.801724\n",
      "4   CHEMBL1006  CHEMBL1002    0.119048  0.880952      1.402826   10.380872\n",
      "\n",
      "----------------------------------------------------------------\n",
      "\n",
      "First 5 entries of processed Target similarity matrix:\n",
      "\n",
      "          Source         Target  Similarity  Distance  Z_Similarity  \\\n",
      "0  CHEMBL1075132  CHEMBL1075104    0.009525  0.990475      0.172216   \n",
      "1  CHEMBL1075133  CHEMBL1075104    0.048693  0.951307      0.880368   \n",
      "2  CHEMBL1075133  CHEMBL1075132    0.006654  0.993346      0.120297   \n",
      "3  CHEMBL1075144  CHEMBL1075104    0.000348  0.999652      0.006292   \n",
      "4  CHEMBL1075144  CHEMBL1075132    0.000919  0.999081      0.016619   \n",
      "\n",
      "   Z_Distance  \n",
      "0   17.907846  \n",
      "1   17.199694  \n",
      "2   17.959765  \n",
      "3   18.073769  \n",
      "4   18.063443  \n",
      "\n",
      "----------------------------------------------------------------\n",
      "\n",
      "Technical information for processed Ligand similarity matrix:\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 758296 entries, 0 to 758295\n",
      "Data columns (total 6 columns):\n",
      "Source          758296 non-null object\n",
      "Target          758296 non-null object\n",
      "Similarity      758296 non-null float64\n",
      "Distance        758296 non-null float64\n",
      "Z_Similarity    758296 non-null float64\n",
      "Z_Distance      758296 non-null float64\n",
      "dtypes: float64(4), object(2)\n",
      "memory usage: 121.9 MB\n",
      "None\n",
      "\n",
      "----------------------------------------------------------------\n",
      "\n",
      "Technical information for processed Target similarity matrix:\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 401856 entries, 0 to 401855\n",
      "Data columns (total 6 columns):\n",
      "Source          401856 non-null object\n",
      "Target          401856 non-null object\n",
      "Similarity      401856 non-null float64\n",
      "Distance        401856 non-null float64\n",
      "Z_Similarity    401856 non-null float64\n",
      "Z_Distance      401856 non-null float64\n",
      "dtypes: float64(4), object(2)\n",
      "memory usage: 63.8 MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import stats\n",
    "\n",
    "# Load similarity matrices to memory\n",
    "def LoadSimMat2DataFrame(simmat, named_df):\n",
    "    ''' Load file matrix to a Pandas DataFrame, ignoring self loops. '''\n",
    "    \n",
    "    source = []\n",
    "    target = []\n",
    "    similarity = []\n",
    "    \n",
    "    with open(simmat, 'r') as f:\n",
    "        for i, line in enumerate(f):\n",
    "            for j, sim in enumerate(line.split()):\n",
    "                if i != j and sim != '':\n",
    "                    source.append(named_df.at[int(i), 'ChEMBL_ID'])\n",
    "                    target.append(named_df.at[int(j), 'ChEMBL_ID'])\n",
    "                    similarity.append(float(sim))\n",
    "                \n",
    "    df = pd.DataFrame({'Source': source, 'Target': target, 'Similarity': similarity})\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Other dataframe functions\n",
    "def df_SetFold(df):\n",
    "    ''' Convert dataframe index into fold identifier. '''\n",
    "    \n",
    "    def _lastDigit(n): return (n % 10)\n",
    "    \n",
    "    df['Fold'] = df.index\n",
    "    df['Fold'] = df['Fold'].apply(_lastDigit)\n",
    "\n",
    "def df_NormalizeSimilarity(df):\n",
    "    ''' Set range of similarity score from 0 to 100. '''\n",
    "\n",
    "    value = 100 / float(df['Similarity'][df['Similarity']==df['Similarity'].max()].head(1))\n",
    "    df['Similarity'] *= value\n",
    "    df['Similarity'] /= 100\n",
    "    \n",
    "def df_GetDistanceAndZScores(df):\n",
    "    ''' Calculate distance measures and Z-Scores of both measures. '''\n",
    "    \n",
    "    df['Distance'] = 1 - df['Similarity']\n",
    "    df['Z_Similarity'] = stats.zscore(df['Similarity'])\n",
    "    df['Z_Distance'] = stats.zscore(df['Distance'])\n",
    "    \n",
    "def df_Transform2Positives(df, columns):\n",
    "    ''' Convert all values to positives of given columns by adding the minimum value to every entry. '''\n",
    "    \n",
    "    for column in list(columns):\n",
    "        value = float(df[column][df[column]==df[column].min()].head(1))\n",
    "        if value < 0:\n",
    "            df[column] += (value * -1)\n",
    "        else:\n",
    "            print('DataFrame column does not comply with requirements (No negative values found)')\n",
    "\n",
    "def df_Convert2Numeric(df, columns):\n",
    "    ''' Convert all values to positives of given columns by adding the minimum value to every entry. '''\n",
    "    \n",
    "    for column in list(columns):\n",
    "        df[column] = df[column].astype('float')\n",
    "\n",
    "df_SetFold(df_ligands)\n",
    "\n",
    "sim_ligands = LoadSimMat2DataFrame(ligands_simmat, df_ligands)\n",
    "\n",
    "df_NormalizeSimilarity(sim_ligands)\n",
    "df_GetDistanceAndZScores(sim_ligands)\n",
    "df_Transform2Positives(sim_ligands, ['Z_Similarity', 'Z_Distance'])\n",
    "df_Convert2Numeric(sim_ligands, ['Similarity', 'Distance', 'Z_Similarity', 'Z_Distance'])\n",
    "\n",
    "print('First 5 entries of processed Ligand similarity matrix:\\n')\n",
    "print(sim_ligands.head())\n",
    "\n",
    "print('\\n'+'-'*64+'\\n')\n",
    "\n",
    "df_SetFold(df_targets)\n",
    "\n",
    "sim_targets = LoadSimMat2DataFrame(targets_simmat, df_targets)\n",
    "\n",
    "df_NormalizeSimilarity(sim_targets)\n",
    "df_GetDistanceAndZScores(sim_targets)\n",
    "df_Transform2Positives(sim_targets, ['Z_Similarity', 'Z_Distance'])\n",
    "df_Convert2Numeric(sim_targets, ['Similarity', 'Distance', 'Z_Similarity', 'Z_Distance'])\n",
    "\n",
    "print('First 5 entries of processed Target similarity matrix:\\n')\n",
    "print(sim_targets.head())\n",
    "\n",
    "print('\\n'+'-'*64+'\\n')\n",
    "\n",
    "print('Technical information for processed Ligand similarity matrix:\\n')\n",
    "print(sim_ligands.info(memory_usage = 'deep'))\n",
    "\n",
    "print('\\n'+'-'*64+'\\n')\n",
    "\n",
    "print('Technical information for processed Target similarity matrix:\\n')\n",
    "print(sim_targets.info(memory_usage = 'deep'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Information for Ligands similarity graph:\n",
      "\n",
      "Name: Ligands\n",
      "Type: Graph\n",
      "Number of nodes: 1232\n",
      "Number of edges: 758296\n",
      "Average degree: 1231.0000\n",
      "Edge attributes: Similarity, Distance, Z_Similarity, Z_Distance, Type\n",
      "Node attributes: Type\n",
      "\n",
      "----------------------------------------------------------------\n",
      "\n",
      "Information for Targets similarity graph:\n",
      "\n",
      "Name: Targets\n",
      "Type: Graph\n",
      "Number of nodes: 897\n",
      "Number of edges: 401856\n",
      "Average degree: 896.0000\n",
      "Edge attributes: Similarity, Distance, Z_Similarity, Z_Distance, Type\n",
      "Node attributes: Type\n",
      "\n",
      "----------------------------------------------------------------\n",
      "\n",
      "Information for DTI (Interactions) graph:\n",
      "\n",
      "Name: Interactions\n",
      "Type: Graph\n",
      "Number of nodes: 2129\n",
      "Number of edges: 9641\n",
      "Average degree:   9.0568\n",
      "Edge attributes: Similarity, Distance, Z_Similarity, Z_Distance, Type\n"
     ]
    }
   ],
   "source": [
    "import networkx as nx\n",
    "\n",
    "# Create graph objects in networkX\n",
    "Ligands_Graph = nx.from_pandas_edgelist(sim_ligands, 'Source', 'Target', edge_attr = True)\n",
    "Ligands_Graph = nx.Graph(Ligands_Graph, name = 'Ligands')\n",
    "nx.set_node_attributes(Ligands_Graph, 'Ligand', 'Type')\n",
    "nx.set_edge_attributes(Ligands_Graph, 'LL', 'Type')\n",
    "\n",
    "Targets_Graph = nx.from_pandas_edgelist(sim_targets, 'Source', 'Target', edge_attr = True)\n",
    "Targets_Graph = nx.Graph(Targets_Graph, name = 'Targets')\n",
    "nx.set_node_attributes(Targets_Graph, 'Target', 'Type')\n",
    "nx.set_edge_attributes(Targets_Graph, 'TT', 'Type')\n",
    "\n",
    "Interactions_Graph = nx.from_pandas_edgelist(df_interactions, 'Ligand', 'Target')\n",
    "Interactions_Graph = nx.Graph(Interactions_Graph, name = 'Interactions')\n",
    "nx.set_edge_attributes(Interactions_Graph, 'LT', 'Type')\n",
    "nx.set_edge_attributes(Interactions_Graph, 100, 'Similarity')\n",
    "nx.set_edge_attributes(Interactions_Graph, 100, 'Distance')\n",
    "nx.set_edge_attributes(Interactions_Graph, 100, 'Z_Similarity')\n",
    "nx.set_edge_attributes(Interactions_Graph, 100, 'Z_Distance')\n",
    "nx.set_node_attributes(Interactions_Graph, dict(zip(df_ligands.ChEMBL_ID, df_ligands.Fold)), 'Fold')\n",
    "nx.set_node_attributes(Interactions_Graph, dict(zip(df_targets.ChEMBL_ID, df_targets.Fold)), 'Fold')\n",
    "\n",
    "print('Information for Ligands similarity graph:\\n')\n",
    "print(nx.info(Ligands_Graph))\n",
    "print('Edge attributes:', ', '.join(list((list(Ligands_Graph.edges(data=True))[0][2]).keys())))\n",
    "print('Node attributes:', ', '.join(list((list(Ligands_Graph.nodes(data=True))[0][1]).keys())))\n",
    "\n",
    "print('\\n'+'-'*64+'\\n')\n",
    "\n",
    "print('Information for Targets similarity graph:\\n')\n",
    "print(nx.info(Targets_Graph))\n",
    "print('Edge attributes:', ', '.join(list((list(Targets_Graph.edges(data=True))[0][2]).keys())))\n",
    "print('Node attributes:', ', '.join(list((list(Targets_Graph.nodes(data=True))[0][1]).keys())))\n",
    "\n",
    "print('\\n'+'-'*64+'\\n')\n",
    "\n",
    "print('Information for DTI (Interactions) graph:\\n')\n",
    "print(nx.info(Interactions_Graph))\n",
    "print('Edge attributes:', ', '.join(list((list(Targets_Graph.edges(data=True))[0][2]).keys())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Information for Master graph:\n",
      "\n",
      "Name: Complete graph\n",
      "Type: Graph\n",
      "Number of nodes: 2129\n",
      "Number of edges: 1169793\n",
      "Average degree: 1098.9131\n",
      "Edge attributes: Similarity, Distance, Z_Similarity, Z_Distance, Type\n",
      "Node attributes: Type, Fold\n",
      "\n",
      "Saved graph as .graphml file.\n"
     ]
    }
   ],
   "source": [
    "# Merge all graphs into master graph and save as GraphML\n",
    "Master_Graph = nx.compose_all([Ligands_Graph, Targets_Graph, Interactions_Graph])\n",
    "Master_Graph = nx.Graph(Master_Graph, name = 'Complete graph')\n",
    "\n",
    "print('Information for Master graph:\\n')\n",
    "print(nx.info(Master_Graph))\n",
    "print('Edge attributes:', ', '.join(list((list(Master_Graph.edges(data=True))[0][2]).keys())))\n",
    "print('Node attributes:', ', '.join(list((list(Master_Graph.nodes(data=True))[0][1]).keys())))\n",
    "\n",
    "nx.write_graphml(Master_Graph, interactions_file + '.graphml')\n",
    "print('\\nSaved graph as .graphml file.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'graph_tool'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-96db4979c053>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mgraph_tool\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mgt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# Convert the master graph from networkx to Graph-Tool using Kuan Butts code and save as .graphml file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# and binary graph file (.gt).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m#\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'graph_tool'"
     ]
    }
   ],
   "source": [
    "import graph_tool.all as gt\n",
    "\n",
    "# Convert the master graph from networkx to Graph-Tool using Kuan Butts code and save as .graphml file\n",
    "# and binary graph file (.gt).\n",
    "#\n",
    "# Link to blog post: http://kuanbutts.com/2018/08/17/peartree-to-graph-tool/\n",
    "# TODO: Ask for personal information for acknowledgement\n",
    "\n",
    "def get_prop_type(value, key=None):\n",
    "    \"\"\"\n",
    "    Performs typing and value conversion for the graph_tool PropertyMap class.\n",
    "    If a key is provided, it also ensures the key is in a format that can be\n",
    "    used with the PropertyMap. Returns a tuple, (type name, value, key)\n",
    "    \"\"\"\n",
    "    # Ensure that key is returned as a str type\n",
    "    if isinstance(key, bytes):\n",
    "        key = key.decode()\n",
    "\n",
    "    # Deal with the value\n",
    "    if isinstance(value, bool):\n",
    "        tname = 'bool'\n",
    "\n",
    "    elif isinstance(value, int):\n",
    "        tname = 'float'\n",
    "        value = float(value)\n",
    "\n",
    "    elif isinstance(value, float):\n",
    "        tname = 'float'\n",
    "\n",
    "    elif isinstance(value, bytes):\n",
    "        tname = 'string'\n",
    "        value = value.decode()\n",
    "\n",
    "    elif isinstance(value, dict):\n",
    "        tname = 'object'\n",
    "\n",
    "    else:\n",
    "        tname = 'string'\n",
    "        value = str(value)\n",
    "\n",
    "    return tname, value, key\n",
    "\n",
    "def nx2gt(nxG):\n",
    "    \"\"\"\n",
    "    Converts a networkx graph to a graph-tool graph.\n",
    "    \"\"\"\n",
    "    # Phase 0: Create a directed or undirected graph-tool Graph\n",
    "    gtG = gt.Graph(directed=nxG.is_directed())\n",
    "\n",
    "    # Add the Graph properties as \"internal properties\"\n",
    "    for key, value in nxG.graph.items():\n",
    "        # Convert the value and key into a type for graph-tool\n",
    "        tname, value, key = get_prop_type(value, key)\n",
    "\n",
    "        prop = gtG.new_graph_property(tname) # Create the PropertyMap\n",
    "        gtG.graph_properties[key] = prop     # Set the PropertyMap\n",
    "        gtG.graph_properties[key] = value    # Set the actual value\n",
    "\n",
    "    # Phase 1: Add the vertex and edge property maps\n",
    "    # Go through all nodes and edges and add seen properties\n",
    "    # Add the node properties first\n",
    "    nprops = set() # cache keys to only add properties once\n",
    "    for node, data in nxG.nodes(data=True):\n",
    "\n",
    "        # Go through all the properties if not seen and add them.\n",
    "        for key, val in data.items():\n",
    "            if key in nprops: continue # Skip properties already added\n",
    "\n",
    "            # Convert the value and key into a type for graph-tool\n",
    "            tname, _, key  = get_prop_type(val, key)\n",
    "\n",
    "            prop = gtG.new_vertex_property(tname) # Create the PropertyMap\n",
    "            gtG.vertex_properties[key] = prop     # Set the PropertyMap\n",
    "\n",
    "            # Add the key to the already seen properties\n",
    "            nprops.add(key)\n",
    "\n",
    "    # Also add the node id: in NetworkX a node can be any hashable type, but\n",
    "    # in graph-tool node are defined as indices. So we capture any strings\n",
    "    # in a special PropertyMap called 'id' -- modify as needed!\n",
    "    gtG.vertex_properties['ID'] = gtG.new_vertex_property('string')\n",
    "\n",
    "    # Add the edge properties second\n",
    "    eprops = set() # cache keys to only add properties once\n",
    "    for src, dst, data in nxG.edges(data=True):\n",
    "\n",
    "        # Go through all the edge properties if not seen and add them.\n",
    "        for key, val in data.items():\n",
    "            if key in eprops: continue # Skip properties already added\n",
    "\n",
    "            # Convert the value and key into a type for graph-tool\n",
    "            tname, _, key = get_prop_type(val, key)\n",
    "\n",
    "            prop = gtG.new_edge_property(tname) # Create the PropertyMap\n",
    "            gtG.edge_properties[key] = prop     # Set the PropertyMap\n",
    "\n",
    "            # Add the key to the already seen properties\n",
    "            eprops.add(key)\n",
    "\n",
    "    # Phase 2: Actually add all the nodes and vertices with their properties\n",
    "    # Add the nodes\n",
    "    vertices = {} # vertex mapping for tracking edges later\n",
    "    for node, data in nxG.nodes(data=True):\n",
    "\n",
    "        # Create the vertex and annotate for our edges later\n",
    "        v = gtG.add_vertex(n=1)\n",
    "        vertices[node] = v\n",
    "\n",
    "        # Set the vertex properties, not forgetting the id property\n",
    "        data['ID'] = str(node)\n",
    "        for key, value in data.items():\n",
    "            tname, value, key = get_prop_type(value, key)\n",
    "            gtG.vp[key][v] = value # vp is short for vertex_properties\n",
    "\n",
    "    # Add the edges\n",
    "    for src, dst, data in nxG.edges(data=True):\n",
    "\n",
    "        # Look up the vertex structs from our vertices mapping and add edge.\n",
    "        e = gtG.add_edge(vertices[src], vertices[dst])\n",
    "\n",
    "        # Add the edge properties\n",
    "        for key, value in data.items():\n",
    "            gtG.ep[key][e] = value # ep is short for edge_properties\n",
    "\n",
    "    # Done, finally!\n",
    "    return gtG\n",
    "\n",
    "Master_Graph_gt = nx2gt(Master_Graph)\n",
    "\n",
    "print('Information for Master graph as Graph-Tool object:\\n')\n",
    "print(Master_Graph_gt)\n",
    "\n",
    "Master_Graph_gt.save(interactions_file+'.gt')\n",
    "print('Saved graph object to binary file format.')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
